## Компоненты

### API-парсер (основной)

- **`parser.py`** - основной парсер, собирает данные через API Power BI (type hints для mypy)
  - Поддерживает обработку районов и их подрайонов
  - Автоматически раскрывает иерархию районов и собирает данные для всех уровней
- **`runner.py`** - оркестратор, управляет батчами парсера и трансформацией (type hints для mypy --strict)
- **`transform_metrics_areas.py`** - преобразует сырые данные в финальный формат (type hints для mypy --strict)
- **`config.json`** - централизованная конфигурация парсера
- **`mypy.ini`** - конфигурация для проверки типов (mypy)

### Обработка подрайонов

Парсер автоматически обрабатывает иерархическую структуру районов:

1. **Раскрытие подрайонов**: При обработке района парсер нажимает на `expandButton` для раскрытия списка подрайонов
2. **Сбор списка подрайонов**: Собирает все элементы с `aria-level="2"` (подрайоны)
3. **Обработка главного района**: Сначала собирает данные для района в целом
4. **Обработка каждого подрайона**: Затем последовательно обрабатывает каждый подрайон

**Структура данных с подрайонами**:

```json
{
  "01.12.2025": {
    "Business Bay": [...данные района в целом...],
    "Business Bay - Churchill Towers": [...данные подрайона...],
    "Business Bay - Executive Towers": [...данные подрайона...],
    "Business Bay - Bay Avenue": [...данные подрайона...],
    "Al Aweer": [...данные района в целом...],
    "Al Aweer - Al Aweer": [...данные подрайона...],
    "Al Aweer - Al Aweer First": [...данные подрайона...],
    "Al Aweer - Al Aweer Second": [...данные подрайона...]
  }
}
```

**Формат ключей**:
- Главный район: `"Название района"` (например, `"Business Bay"`)
- Подрайон: `"Название района - Название подрайона"` (например, `"Business Bay - Churchill Towers"`)

Все районы и подрайоны хранятся на одном уровне внутри даты. Подрайоны отличаются от районов наличием разделителя `" - "` в названии.

### Архитектура батчей

Runner автоматически разбивает районы на батчи:

- **Входной файл**: `all_areas.txt` содержит полный список всех районов (один на строку)
- **Размер батча**: Определяется параметром `batch_size` в config.json (по умолчанию 30 районов)
- **Автоматическое разделение**: Runner загружает все районы и разбивает их на батчи по 30
- **Независимые сессии**: Каждый батч запускается с отдельной сессией браузера для повышения надежности
- **Последовательная обработка**: Батчи обрабатываются один за другим

**Пример**: Если в файле 91 район, будут созданы 3 батча:

- Батч 1: 30 районов
- Батч 2: 30 районов
- Батч 3: 31 район

### Решение проблемы с кэшированием Business Bay

**Проблема**: При загрузке дашборда по умолчанию выбран район "Business Bay". Браузер кэширует API-ответы для этого района. Когда очередь парсера доходит до Business Bay, браузер **не делает** новые запросы, берёт данные из кэша, и парсер их не перехватывает.

**Решение реализованное в парсере**:

1. Перед основным циклом обработки районов парсер обрабатывает дефолтный район (**Business Bay**)
2. В этот момент браузер уже показывает его данные → парсер успешно перехватывает запросы
3. Затем обрабатывает остальные районы из `areas.txt`, автоматически пропуская дефолтный
4. Параметр `default_area` в конфиге позволяет менять дефолтный район если нужно

**Пример flow**:

```
1. Загрузка дашборда → Business Bay загружается по умолчанию
2. [PROCESSING] Business Bay (перехватываем его данные прямо сейчас)
3. [PROCESSING] The Lakes
4. [PROCESSING] The Springs and The Meadows
... (остальные районы)
```

- Батч 3: 31 район

### Device ID

Device ID сохраняется в local storage браузера после первой авторизации. Чтобы получить свой device ID:

1. Авторизуйтесь вручную в Power BI дашборде
2. Откройте Browser DevTools (F12)
3. Перейдите в Application → Local Storage
4. Найдите ключ `deviceId`
5. Скопируйте значение и подставьте в config.json

## Конфигурация

### Файл config.json

Все параметры парсера находятся в `config.json`:

```json
{
  "auth": {
    "device_id": "123456789",
    "username": "...@gmail.com",
    "password": "YOUR_PASSWORD"
  },
  "areas_file": "all_areas.txt",
  "batch_size": 30,
  "auto": false,
  "date_settings": {
    "start_date": "23.11.2025",
    "end_date": "24.11.2025",
    "everyday": false
  },
  "output_raw_file": "metrics_raw.json",
  "output_merged_file": "metrics_merged.json",
  "output_final_file": "metrics_final.json"
}
```

### Параметры конфигурации

#### `auth` (object)

Параметры аутентификации для Power BI:

- **`device_id`** (строка): ID устройства для авторизации
- **`username`** (строка): Email для входа в Power BI
- **`password`** (строка): Пароль для входа в Power BI

#### `areas_file` (строка)

Имя файла со всеми районами для обработки. Каждый район должен быть на отдельной строке.

#### `batch_size` (число)

Максимальное количество районов в одном батче (по умолчанию 30).

#### `default_area` (строка) *(опционально)*

Название района, который загружается по умолчанию при открытии дашборда (по умолчанию `Business Bay`).

**Назначение**: Решает проблему с кэшированием запросов. Дашборд автоматически загружает один район по умолчанию. Парсер обрабатывает этот район **до** остального списка, когда его данные уже на экране и готовы к перехвату. Затем обрабатывает остальные районы из `areas.txt`, пропуская дефолтный, чтобы избежать повторной обработки и проблем с кэшем.

#### `date_settings` (object)

- **`start_date`** (строка, формат DD.MM.YYYY): Начальная дата для сбора данных
- **`end_date`** (строка, формат DD.MM.YYYY): Конечная дата для сбора данных
- **`everyday`** (boolean): Режим обработки дат
  - `true` - сбор ежедневных снимков для каждого дня в диапазоне
  - `false` - один снимок за весь диапазон дат (от start_date до end_date)

#### `output_raw_file` (строка)

Имя файла для сохранения сырых данных с ответами API.

#### `output_merged_file` (строка)

Имя файла для объединённых данных всех батчей.

#### `output_final_file` (строка)

Имя файла для финального трансформированного результата.

#### `auto` (boolean) *(опционально)*

Режим работы парсера:

- `true` - автоматический режим: парсер сам вычисляет прошлую полную неделю (пн-вс) и собирает 7 ежедневных снимков. Имя файла генерируется автоматически как `week_DD_MM_YYYY-DD_MM_YYYY.json`
- `false` - ручной режим: используются даты из `date_settings`

**Примечание**: Когда `auto: true`, параметры `date_settings` и `output_final_file` игнорируются (по умолчанию `false`).

## Использование

Запустите главный скрипт:

```bash
python runner.py
```

Процесс:

1. Парсер загружает конфиг из config.json
2. Валидирует файлы районов
3. Запускает парсер для каждого батча последовательно
4. Объединяет результаты
5. Выполняет трансформацию
6. Сохраняет финальный результат

### Примеры конфигураций

#### Пример 1: Ежедневные снимки за неделю

```json
{
  "date_settings": {
    "start_date": "23.11.2025",
    "end_date": "29.11.2025",
    "everyday": true
  },
  "output_raw_file": "metrics_weekly_raw.json",
  "output_final_file": "metrics_weekly.json"
}
```

Результат: 7 ежедневных снимков (по одному за каждый день).

#### Пример 2: Один снимок за диапазон

```json
{
  "date_settings": {
    "start_date": "23.11.2025",
    "end_date": "29.11.2025",
    "everyday": false
  },
  "output_raw_file": "metrics_range_raw.json",
  "output_final_file": "metrics_range.json"
}
```

Результат: 1 снимок, содержащий сводную статистику за весь диапазон (23.11.2025 - 29.11.2025).

#### Пример 3: Один день

```json
{
  "date_settings": {
    "start_date": "29.11.2025",
    "end_date": "29.11.2025",
    "everyday": false
  }
}
```

#### Пример 4: Автоматический режим (прошлая неделя)

```json
{
  "auto": true
}
```

Результат: Парсер автоматически вычислит прошлую полную неделю (пн-вс) и создаст файл вида `week_24_11_2025-30_11_2025.json` с 7 ежедневными снимками для всех районов.

## Формат выходных данных

### Структура финального файла

```json
{
  "23.11.2025": {
    "The Lakes": {
      "sales_listing_volume": 3.0,
      "rent_listing_volume": 0.0,
      "sales_volume": {
        "ready_properties": 0.0,
        "off_plan_properties": 0.0
      },
      "sales_listing_avg_price": 3418.2,
      "rent_listing_avg_price": 0.0,
      "sales_avg_price": {
        "ready_properties": 0.0,
        "off_plan_properties": 0.0
      },
      "rent_volume": {
        "renewed_rentals": 0.0,
        "new_rentals": 0.0
      },
      "rent_avg_price": {
        "new_rentals": 0.0,
        "renewed_rentals": 0.0
      }
    }
  }
}
```

## Управление районами

### Файл all_areas.txt

Содержит полный список районов, по одному на строку:

```
The Lakes
Jebel Ali
Bur Dubai
Downtown Dubai
...
```

### Добавление новых районов

1. Отредактируйте файл `all_areas.txt`
2. Добавьте названия новых районов, по одному на строку
3. Сохраните файл
4. Запустите парсер - он автоматически разделит все районы на батчи

### Исключение районов

Просто удалите строку с названием района из `all_areas.txt`. Парсер будет работать только с оставшимися районами.

### Изменение размера батча

Измените параметр `batch_size` в config.json:

```json
{
  "batch_size": 20
}
```

Парсер автоматически создаст батчи нужного размера.

## Проверка типов (Type Hints)

Все основные файлы содержат полные аннотации типов для проверки с помощью mypy:

### Проверка типов

```bash
mypy runner.py --strict
mypy transform_metrics_areas.py --strict
```

### Конфигурация mypy

Файл `mypy.ini` содержит конфигурацию для проверки типов:

- Python версия: 3.9+
- Playwright импорты игнорируются (нет type stubs)
- Все остальные типы проверяются в strict режиме

## Обработка ошибок

### Пустой файл all_areas.txt

Если файл `all_areas.txt` пуст, парсер выведет ошибку:

```
[ERROR] Файл all_areas.txt пуст
```

**Решение**: Добавьте районы в файл.

## Структура проекта

```
Parsing Reidin/
├── parser.py                      # Основной парсер (с type hints)
├── runner.py                      # Оркестратор (с type hints)
├── transform_metrics_areas.py     # Трансформер данных (с type hints)
├── config.json                    # Конфигурация
├── mypy.ini                       # Конфигурация для mypy
├── requirements.txt               # Зависимости Python
├── README.md                      # Документация
├── all_areas.txt                  # Все районы (один на строку)
├── areas.txt                      # Временный файл (районы текущего батча)
├── metrics_*_raw.json             # Сырые данные API
├── metrics_*_merged.json          # Объединённые данные
└── *.json                         # Финальные данные (автоматическое имя)
```

## Логирование

Парсер выводит подробные логи процесса обработки:

```
======================================================================
[START] Главный скрипт запуска парсера Reidin
[TIME] 2025-12-02 15:52:33
======================================================================

[INFO] Загружаю config.json...
[INFO] Режим: AUTO
[INFO] Автоматический режим: прошлая неделя (24.11.2025 - 30.11.2025)

[INFO] Параметры дат:
  Start: 24.11.2025
  End: 30.11.2025
  Everyday: True

[OK] Загружено 91 районов из all_areas.txt
[OK] Разбито на 4 батчей по 30 районов

======================================================================
[BATCH 1/4] Обработка 30 районов
[OUTPUT] Raw file: metrics_raw.json
[DATES] 24.11.2025 - 30.11.2025 (everyday: True)
======================================================================

[OK] Батч 1 завершен успешно

...

[BATCH 4/4] Обработка 1 районов
[OUTPUT] Raw file: metrics_raw.json
[DATES] 24.11.2025 - 30.11.2025 (everyday: True)
======================================================================

[OK] Батч 4 завершен успешно

======================================================================
[MERGE] Объединяю результаты...
[INPUT] metrics_raw.json (один для каждого батча)
[OUTPUT] metrics_merged.json
======================================================================

[OK] Объединение завершено!
  Дат: 7
  Всего уникальных районов: 91
  Файл: metrics_merged.json

======================================================================
[TRANSFORM] Запуск трансформации...
======================================================================

[OK] Трансформация завершена успешно

======================================================================
[FINISH] Завершено!
[TIME] 2025-12-02 16:57:55
======================================================================

Финальный результат: week_24_11_2025-30_11_2025.json
  Дат: 7
  Районов: 91
```

## Excel-парсеры (Dashboard экспорты)

### Описание

Три дополнительных парсера для экспорта данных из Power BI Dashboard в формате Excel с последующей конвертацией в JSON.

Конвертация и слив данных происходит автоматом. Но можно запускать их по отдельности, если есть готовые таблицы. Как пример, скачали таблиц Yields сколько нужно. Запустили `convert_yields` он конвертирует в json, запустили `merge_yields`, он сольет все в один файл.

### Парсер 1: Price Trends (Dashboard 1117)

- **`parser_price_trends.py`** - скачивает Sales & Rent Price Trend таблицы
- **`convert_price_trends.py`** - конвертирует XLSX в JSON с автоопределением типа данных
- **`merge_price_trends.py`** - объединяет все JSON в два итоговых файла
- **Dashboard**: https://insight.reidin.com/home/dashboard/1117
- **Логика парсера**: Property (все) → Date (01.01.2003) → City loop (все города) → Property Type loop (Apartment, Villa) → Скачивание Sales + Rent Price Trend
- **Выходные файлы**: `sales_price_trend.json`, `rent_price_trend.json`
- **Структура данных**:
  ```
  {
    city: {
      type: {
        date: {
          location: {
            average_sales_price (или average_rent_price): number,
            mom_change_percent: number | null,
            qoq_change_percent: number | null,
            yoy_change_percent: number | null
          }
        }
      }
    }
  }
  ```

### Парсер 2: Property Data (Dashboard 996)

- **`parser_property_data.py`** - скачивает данные по конкретным объектам недвижимости
- **`convert_property_data.py`** - конвертирует XLSX в JSON
- **`merge_property_data.py`** - объединяет все JSON в два итоговых файла
- **Dashboard**: https://insight.reidin.com/home/dashboard/996
- **Логика парсера**: Property (все) → Date (01.01.2003) → City loop (все города) → Property Type loop (динамическое определение типов для каждого города) → Скачивание Sales + Rent Property Data
- **Выходные файлы**: `sales_property_data.json`, `rent_property_data.json`
- **Структура данных**:
  ```
  {
    city: {
      type: {
        date: {
          property_name: {
            average_sales_price (или average_rent_price): number
          }
        }
      }
    }
  }
  ```

### Парсер 3: Yields (Dashboard 997)

- **`parser_yields.py`** - скачивает данные по доходности (Gross Yield)
- **`convert_yields.py`** - конвертирует XLSX в JSON
- **`merge_yields.py`** - объединяет все JSON в один итоговый файл
- **Dashboard**: https://insight.reidin.com/home/dashboard/997
- **Логика парсера**: Property (все) → Date (01.01.2003) → City loop (все города) → Property Type loop (динамическое определение типов) → Скачивание Yields
- **Выходной файл**: `yields_data.json`
- **Структура данных**:
  ```
  {
    city: {
      type: {
        date: {
          location: {
            gross_yield_percent: number
          }
        }
      }
    }
  }
  ```

### Парсер 4: Rental Yields (Dashboard 1118)

- **`parser_rental_yields.py`** - скачивает данные по доходности аренды (Rental Yields) с детализацией по количеству спален
- **`convert_rental_yields.py`** - конвертирует XLSX в JSON
- **`merge_rental_yields.py`** - объединяет все JSON в один итоговый файл с хронологической сортировкой дат
- **Dashboard**: https://insight.reidin.com/home/dashboard/1118
- **Логика парсера**: Property (все) → Date (01.01.2003) → Location (все) → City loop (все города) → Property Type loop (Apartment, Villa) → Bedrooms loop (All, 0/Studio, 1-6 Bedrooms) → Скачивание Rental Yields
- **Выходной файл**: `rental_yields_data.json`
- **Структура данных**:
  ```
  {
    city: {
      type: {
        date: {
          location: {
            bedroom_key: rental_yields_percent (number)
          }
        }
      }
    }
  }
  ```

  где `bedroom_key` = "all" | "0" | "1" | "2" | "3" | "4" | "5" | "6"
- **Особенности**:
  - Данные до 2017 года содержат только "all" (без разбивки по спальням)
  - С 2017 года доступны детальные данные по каждому типу спален (0, 1, 2, 3, 4, 5, 6, all)
  - Даты автоматически сортируются хронологически при объединении (от самой ранней к самой поздней)

### Использование

Каждый парсер запускается отдельно и работает полностью автономно:

```bash
python parser_price_trends.py
python parser_property_data.py
python parser_yields.py
python parser_rental_yields.py
```

**Рекомендуемый режим**: Настройте cron/Task Scheduler для автоматического запуска каждого парсера раз в месяц.

**Что происходит при запуске парсера:**

1. Скачивание всех XLSX таблиц для всех комбинаций городов и типов объектов
2. Автоматическая конвертация XLSX → JSON
3. Автоматическое объединение всех JSON в итоговые файлы
4. Автоматическая очистка промежуточных файлов (XLSX после конвертации, JSON после объединения)

**Пример cron для ежемесячного запуска (1-го числа в 3:00):**

```cron
0 3 1 * * cd /path/to/Parsing-Reidin && .venv/bin/python parser_price_trends.py
0 4 1 * * cd /path/to/Parsing-Reidin && .venv/bin/python parser_property_data.py
0 5 1 * * cd /path/to/Parsing-Reidin && .venv/bin/python parser_yields.py
0 6 1 * * cd /path/to/Parsing-Reidin && .venv/bin/python parser_rental_yields.py
```

## Лицензия

Приватный проект.

## Поддержка

Для вопросов и проблем зовите @zont1kk.
